в порядке обзора:
рассмотрел bigquery-public-data chicago_taxi_trips
сделал запросы, например:
SELECT count(1) as cnt_, sum(trip_total) as sum_total  , company, 
    FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips` 
    GROUP BY company
    order by 1 desc
    limit 100;

читает 5гб,  в зависимости от кеширования отрабатывает до 2 сек.

создаем bucket/каталог gs (google cloud storage) gs://pg-bigdata/chicago_taxitrips/
экспортируем датасет в gs://pg-bigdata/chicago_taxitrips/


sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list' 
wget --quiet -O -    https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add  - 
sudo apt-get update ; sudo apt-get -y install postgresql-13

подключаем диск на 100гб, 
создаем раздел, 
форматируем, 
монтируем в каталог /var/lib/postgresql/13 где располагается сервер.
прописываем необходимые измнения в /etc/fstab чтобы он монтировался при старте операционной системы.


создаем там каталог для данных скачанных с gc
качаю первых 40 файлов. это объем порядка 20гб
gsutil -m cp gs://pg-bigdata/chicago_taxitrips/data0000000000{0,1,2,3}*.csv /var/lib/postgresql/13/data/
это даст мне порядка 10 гб сырых данных.

настраиваем сервер так, чтобы побыстрее прогрузить initial load(я могу себе в этом случае позволить).



ALTER SYSTEM SET synchronous_commit = 'off';
ALTER SYSTEM SET max_wal_senders = 0; -- требует wal_level = minimal
ALTER SYSTEM SET wal_level = minimal;
ALTER SYSTEM SET fsync=off;
ALTER SYSTEM SET full_page_writes=off;


для работы с table создал базу taxi 

create table taxi_trips (
unique_key text, 
taxi_id text, 
trip_start_timestamp TIMESTAMP, 
trip_end_timestamp TIMESTAMP, 
trip_seconds bigint, 
trip_miles numeric, 
pickup_census_tract bigint, 
dropoff_census_tract bigint, 
pickup_community_area bigint, 
dropoff_community_area bigint, 
fare numeric, 
tips numeric, 
tolls numeric, 
extras numeric, 
trip_total numeric, 
payment_type text, 
company text, 
pickup_latitude numeric, 
pickup_longitude numeric, 
pickup_location text, 
dropoff_latitude numeric, 
dropoff_longitude numeric, 
dropoff_location text
);

/* причина выбора этого датасета была в том, чтобы не вычислять DDL create table */ 

убедившись что загрузка отрабатывает:
COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) 
FROM '/var/lib/postgresql/13/data/data000000000000.csv' DELIMITER ',' CSV HEADER;

truncate, и сформирую скрипт который зальет  все данные.

for file in /var/lib/postgresql/13/data/data*.csv; 
do
	echo -e "Processing $file file..."
	psql -d taxi -c "\\COPY taxi_trips(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) FROM '$file' DELIMITER ',' CSV HEADER;"
done

в таком режиме скорость заливки примерно порядка 25 сек на файл 630тыс записей. 40 файлов = 25 млн записей.


Описать что и как делали и с какими проблемами столкнулись.

taxi=# SELECT count(1) as cnt_, sum(trip_total) as sum_total  , company 
    FROM taxi_trips 
    GROUP BY company
    order by 1 desc
    limit 100;
Time: 721295.932 ms (12:01.296)



SELECT payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c FROM taxi_trips group by payment_type order by 3 limit 10;
Time: 673418.743 ms (11:13.419)


попробуем ускорить?
первое очевидное - pgtune в режиме DWH:

max_connections = 20
shared_buffers = 2GB
effective_cache_size = 6GB
maintenance_work_mem = 1GB
checkpoint_completion_target = 0.9
wal_buffers = 16MB
default_statistics_target = 500
random_page_cost = 1.1
effective_io_concurrency = 200
work_mem = 26214kB
min_wal_size = 4GB
max_wal_size = 16GB
max_worker_processes = 4
max_parallel_workers_per_gather = 2
max_parallel_workers = 4
max_parallel_maintenance_workers = 2

основное время уходит на random read таблиц:
SELECT payment_type, round(sum(tips)/sum(trip_total)*100, 0) + 0 as tips_percent, count(*) as c FROM taxi_trips group by payment_type order by 3 limit 10;
Time: 684075.375 ms (11:24.075)

2.
попытка использовать индексы по столбцам:
(каждый индекс создается 20+минут)

CREATE INDEX CONCURRENTLY  ind_trip_total ON taxi_trips (trip_total);
CREATE INDEX CONCURRENTLY  ind_company ON taxi_trips (company);
CREATE INDEX CONCURRENTLY  ind_payment_type ON taxi_trips (payment_type);
CREATE INDEX CONCURRENTLY  ind_tips ON taxi_trips (tips);

3. специализированные индексы для запросов:

CREATE INDEX CONCURRENTLY  ind_q1 ON taxi_trips (company) INCLUDE (trip_total,trip_total)
CREATE INDEX CONCURRENTLY  ind_q2 ON taxi_trips (payment_type) INCLUDE (tips,trip_total)

4. расширение.

git clone https://github.com/citusdata/cstore_fdw

sudo apt-get -y install protobuf-c-compiler libprotobuf-c-dev

# проверка доступости pg_config в PATH
which pg_config 

sudo apt-get -y install make gcc
# по факту ошибки  cstore_fdw.c:17:10: fatal error: postgres.h: No such file or directory
sudo apt -y install postgresql-server-dev-13     

cd cstore_fdw
make ;  make install 
можно убедиться что расширение  cstore_fdw.so находится в  /usr/lib/postgresql/13/lib/cstore_fdw.so

добавляем в конфиг:
shared_preload_libraries = 'cstore_fdw'
рестарт.

CREATE EXTENSION cstore_fdw;
CREATE SERVER cstore_server FOREIGN DATA WRAPPER cstore_fdw;


-- create foreign table
CREATE FOREIGN TABLE taxi_trips_cs (
unique_key text, 
taxi_id text, 
trip_start_timestamp TIMESTAMP, 
trip_end_timestamp TIMESTAMP, 
trip_seconds bigint, 
trip_miles numeric, 
pickup_census_tract bigint, 
dropoff_census_tract bigint, 
pickup_community_area bigint, 
dropoff_community_area bigint, 
fare numeric, 
tips numeric, 
tolls numeric, 
extras numeric, 
trip_total numeric, 
payment_type text, 
company text, 
pickup_latitude numeric, 
pickup_longitude numeric, 
pickup_location text, 
dropoff_latitude numeric, 
dropoff_longitude numeric, 
dropoff_location text
)
SERVER cstore_server
OPTIONS(compression 'pglz');

COPY taxi_trips_cs(unique_key, taxi_id, trip_start_timestamp, trip_end_timestamp, trip_seconds, trip_miles, pickup_census_tract, dropoff_census_tract, pickup_community_area, dropoff_community_area, fare, tips, tolls, extras, trip_total, payment_type, company, pickup_latitude, pickup_longitude, pickup_location, dropoff_latitude, dropoff_longitude, dropoff_location) 
FROM '/var/lib/postgresql/13/data/data000000000000.csv' DELIMITER ',' CSV HEADER;


CREATE INDEX CONCURRENTLY  ind_trip_total ON taxi_trips (trip_total);
CREATE INDEX CONCURRENTLY  ind_company ON taxi_trips (company);
CREATE INDEX CONCURRENTLY  ind_tips ON taxi_trips (tips);





не забыть очистить бакет и остановить машину
